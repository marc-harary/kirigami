# Kirigami

[![arXiv](https://img.shields.io/badge/arXiv-2406.02381-b31b1b.svg)](https://arxiv.org/abs/2406.02381)

[**Kirigami: large convolutional kernels improve deep learning-based RNA secondary structure prediction**](https://arxiv.org/abs/2406.02381)

From [Wikipedia](https://en.wikipedia.org/wiki/Kirigami):

> Kirigami (切り紙) is a variation of origami, the Japanese art of folding paper. In kirigami, the paper is cut as well as being folded, resulting in a three-dimensional design that stands away from the page.

The Kirigami pipeline both folds RNA molecules via a fully convolutional neural network (FCN) and uses Nussinov-style dynamic programming to recursively cut them into subsequences for pre- and post-processing.

Kirigami obtains state-of-the-art (SOTA) performance on the bpRNA test set. Below is the table of results of Kirigami and other SOTA models on TS0:
<img src="figs/repo-fig1.svg">

## Installation

The easiest way to download and interact with Kirigami is via [PyTorch Hub](https://pytorch.org/hub/). Simply run
```python
import torch
model = torch.hub.load('marc-harary/kirigami', 'kirigami', pretrained=True)
print(model("UUCCUGACAAUAUUAUCGCGAUAGAACCACCUGAAUCCAUACCGAACUCAGAAGUGAAAUGUCGUAGUUCCGAUGGUAGUGUGAGGUUUCCUUAUGUGAGAGUAGGAGAUUGUCAGGAAA"))
# .(((((((((......(((((((....(((((((.............))))..)))...)))))).).(((.((....((((((((...))))))))....)).)))..)))))))))..
```
This snippet will automatically pull and cache this repo for immediate deployment.

## Usage

The `model` object above is an instance of `kirigami/learner/KirigamiModule`, which inherits from [`pytorch_lightning.LightningModule`](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html). For convenience, we have implemented a `__call__` method that:
1. Accepts a raw FASTA string,
2. Embeds it as tensor,
3. Maps the resulting input tensor to an predicted output label tensor, and finally
4. Converts the label tensor to a string in [dot-bracket notation (DBN)](https://gensoft.pasteur.fr/docs/ViennaRNA/2.4.14/rna_structure_notations.html#:~:text=Structure%20(WUSS)%20notation-,Dot%2DBracket%20Notation%20(a.k.a.%20Dot%2DParenthesis%20Notation),and%20unpaired%20nucleotides%20by%20dots%20.%20.).
A single method method call is ``all you need.''

## (Re)training

All experiments were performed via [PyTorch Lightning](https://lightning.ai/docs/pytorch/stable). Although the weights of the production model are located at `weights/main.ckpt`, Kirigami can be retrained with varying hyperparameters. Simply run 
```bash
python run.py fit --help
```
for an exhaustive list of configurations, displayed via [Lightning's CLI](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.cli.LightningCLI.html#lightning.pytorch.cli.LightningCLI).

To perform an exact, globally seeded replication of the experiment that generated the weights, run
```bash
python run.py fit
```
to use the appropriate configuration file.

## Data

Data used for training, validation, and testing are taken from the [bpRNA](https://bprna.cgrb.oregonstate.edu/) database in the form of the standard TR0, VL0, and TS0 datasets used by [SPOT-RNA](https://github.com/jaswindersingh2/SPOT-RNA), [MXfold2](https://github.com/mxfold/mxfold2), and [UFold](https://github.com/uci-cbcl/UFold). Respectively, these contain 10,814, 1,300, and 1,305 non-redundant structures. The `.dbn` files located in this repo were generated by scraping the data originally uploaded by the authors of SPOT-RNA.

The data are currently written to `dbn` files in `data/bpRNA/TR0.dbn`, `data/bpRNA/VL0.dbn`, `data/bpRNA/TS0.dbn` but will be embedded as `torch.Tensor`s by the `kirigami.data.DataModule.prepare_data` method once any of the [`LightningCLI`]( subcommands are run. Please see the documentation for the [LightningDataModule](https://lightning.ai/docs/pytorch/stable/data/datamodule.html) API for more detail.
